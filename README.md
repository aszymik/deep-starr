# DeepSTARR â€“ PyTorch Reimplementation and Extension

This repository contains a **PyTorch reimplementation** of the **DeepSTARR** model originally described in:

> De Almeida, B. P., Reiter, F., Pagani, M., & Stark, A. (2022).
> *DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers.*
> **Nature Genetics, 54**(5), 613â€“624. [https://doi.org/10.1038/s41588-022-01023-5](https://doi.org/10.1038/s41588-022-01023-5)

---

## ðŸ” Overview

DeepSTARR is a convolutional neural network designed to predict **enhancer activity** from raw DNA sequence. This repository provides:

* A faithful **reimplementation of DeepSTARR in PyTorch**
* A script for **comparing Keras and PyTorch model outputs** (`compare_keras_and_pytorch/compare_keras_to_pytorch.py`)
* An **extended flexible version**, **DeepSTARRFlex**, where model architecture (e.g., number of convolutional or fully connected layers) can be specified via parameters
* Tools for training, prediction, contribution analysis, and visualization

---

## ðŸ“ Project Structure

```
deep-starr/
â”œâ”€â”€ compare_keras_and_pytorch/    # Compare original Keras and PyTorch outputs
â”œâ”€â”€ data_processing/              # File preprocessing scripts
â”œâ”€â”€ envs/                         # Conda environments for Keras and PyTorch
â”œâ”€â”€ models/                       # Trained model checkpoints
â”œâ”€â”€ outputs/                      # Model prediction outputs
â”œâ”€â”€ plots/                        # Performance plots
â”œâ”€â”€ plot_scripts/                 # Scripts to generate training and prediction plots
â”œâ”€â”€ train_logs/                   # Training logs per model
â”œâ”€â”€ models.py                     # Model definitions (including DeepSTARRFlex)
â”œâ”€â”€ train.py                      # Train original PyTorch model
â”œâ”€â”€ train_flex_model.py           # Train flexible DeepSTARRFlex model
â”œâ”€â”€ pred_new_sequence.py          # Predict enhancer activity (PyTorch)
â”œâ”€â”€ pred_new_sequence_keras.py    # Predict enhancer activity (Keras)
â”œâ”€â”€ datasets.py                   # Dataset loaders
â”œâ”€â”€ utils.py                      # Utility functions
â”œâ”€â”€ get_data.sh                   # Script to download and prepare data
â””â”€â”€ README.md                     # Project description
```

---

## âš™ï¸ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/your_username/deep-starr.git
cd deep-starr
```

### 2. Set up the environment

* **PyTorch model**:

  ```bash
  conda env create -f envs/pytorch_env.yml
  conda activate deepstarr-pytorch
  ```

* **Keras model**:

  ```bash
  conda env create -f envs/keras_env.yml
  conda activate deepstarr-keras
  ```

### 3. Download data

```bash
bash get_data.sh
```

This will place preprocessed training/validation/test sets in `data/deep-starr/`.

---

## ðŸ§  Model Training

### Train PyTorch DeepSTARR (original architecture)

```bash
python train.py
```

### Train DeepSTARRFlex (custom architecture)

Specify your architecture in `train_flex_model.py`, then run:

```bash
python train_flex_model.py
```

Example parameters you can adjust in `DeepSTARRFlex`:

* Number of convolutional layers
* Number of dense (FC) layers
* Filter sizes and counts
* Dropout rate, padding, etc.

---

## ðŸ” Prediction

### Predict on new sequences (PyTorch)

```bash
python pred_new_sequence.py --fasta data/my_input.fa --model_path models/deep-starr/model.pth
```

### Predict on new sequences (Keras)

```bash
python pred_new_sequence_keras.py --fasta data/my_input.fa --model_path models/deep-starr/model.h5
```

---

## âš–ï¸ Compare Keras and PyTorch Predictions

To verify model translation consistency:

```bash
python compare_keras_and_pytorch/compare_keras_to_pytorch.py
```

This will compute correlation and output comparison plots between the two model types.

---

## ðŸ“ˆ Results and Visualization

* Training logs are saved in `train_logs/`
* Model predictions go to `outputs/`
* Final performance plots (e.g. RÂ², scatter plots) are in `plots/`
* Plotting utilities can be found in `plot_scripts/`

---

## ðŸ“œ Citation

If you use this codebase or find it helpful, please cite the original paper:

> De Almeida, B. P., Reiter, F., Pagani, M., & Stark, A. (2022).
> *DeepSTARR predicts enhancer activity from DNA sequence and enables the de novo design of synthetic enhancers.*
> **Nature Genetics, 54**(5), 613â€“624. [https://doi.org/10.1038/s41588-022-01023-5](https://doi.org/10.1038/s41588-022-01023-5)

---

## ðŸ™‹ Acknowledgements

This project is inspired by the original DeepSTARR implementation in Keras and TensorFlow.
Thanks to the authors for making the model and data publicly available.

---
